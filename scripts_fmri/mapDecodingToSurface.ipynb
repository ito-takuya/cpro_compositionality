{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory notebook for miniblock decoding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import loadTaskBehavioralData as task\n",
    "import tools\n",
    "import multiprocessing as mp\n",
    "import statsmodels.stats.multitest as mc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = '/projects3/CPROCompositionality/'\n",
    "datadir = projectdir + 'data/processedData/' \n",
    "resultdir = projectdir + 'data/results/'\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028',\n",
    "            '030','031','032','033','034','035','037','038','039','040','041',\n",
    "            '042','043','045','046','047','048','049','050','053','055','056',\n",
    "            '057','058','062','063','066','067','068','069','070','072','074',\n",
    "            '075','076','077','081','085','086','087','088','090','092','093',\n",
    "            '094','095','097','098','099','101','102','103','104','105','106',\n",
    "            '108','109','110','111','112','114','115','117','119','120','121',\n",
    "            '122','123','124','125','126','127','128','129','130','131','132',\n",
    "            '134','135','136','137','138','139','140','141']\n",
    "\n",
    "glasser = projectdir + 'data/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser = nib.load(glasser).get_data()\n",
    "glasser = np.squeeze(glasser)\n",
    "rois = np.arange(1,361)\n",
    "\n",
    "#### Load in CAB-NP ROI labels\n",
    "cabn_labels = pd.read_csv(projectdir + 'data/CortexSubcortex_ColeAnticevic_NetPartition_wSubcorGSR_parcels_LR_LabelKey.txt',header=0,delimiter='\\t')\n",
    "df_labels = cabn_labels.iloc[0:360]\n",
    "df_labels.reset_index()\n",
    "del df_labels['INDEX'], df_labels[\"KEYVALUE\"]\n",
    "\n",
    "# Using final partition\n",
    "networkdef = df_labels['NETWORKKEY'].values\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "\n",
    "fpn_ind = np.where(networkdef==networkmappings['fpn'])[0]\n",
    "con_ind = np.where(networkdef==networkmappings['con'])[0]\n",
    "ccn_ind = np.hstack((fpn_ind,con_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results for novelty decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_novelty = pd.read_csv(resultdir + 'CrossSubjectNoveltyDecoding/CrossSubjectNoveltyDecoding_allROIs.csv')\n",
    "rois = np.unique(df_novelty.ROI)\n",
    "accuracy = []\n",
    "ps = []\n",
    "for roi in np.sort(rois):\n",
    "    tmp_df = df_novelty.loc[df_novelty.ROI==roi]\n",
    "    acc = tmp_df.DecodingAccuracy.values\n",
    "    accuracy.append(np.mean(acc))\n",
    "\n",
    "#### Load in accuracies from permutation test\n",
    "nulldist = np.loadtxt(resultdir + 'CrossSubjectNoveltyDecoding/CrossSubjectNoveltyDecoding_NullDistribution.csv')\n",
    "fwe_thresh = np.max(nulldist[ccn_ind,:],axis=0)\n",
    "fwe_thresh = np.sort(fwe_thresh)\n",
    "alpha_ind = int(len(fwe_thresh)*.95)\n",
    "fwe_thresh = fwe_thresh[alpha_ind]\n",
    "\n",
    "qs = mc.fdrcorrection(ps)[0]\n",
    "accuracy = np.asarray(accuracy)\n",
    "data = np.zeros((len(accuracy),2))\n",
    "data[:,0] = accuracy\n",
    "data[ccn_ind,1] = np.multiply(accuracy[ccn_ind],accuracy[ccn_ind]>fwe_thresh)\n",
    "tools.mapBackToSurface(data,resultdir + 'NoveltyDecoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify which regions are sensitive to negations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negation = pd.read_csv(resultdir + 'CrossSubjectLogicalNegationDecoding/CrossSubjectLogicalNegationDecoding_allROIs.csv')\n",
    "rois = np.unique(df_negation.ROI)\n",
    "accuracy = []\n",
    "ps = []\n",
    "for roi in np.sort(rois):\n",
    "    tmp_df = df_negation.loc[df_negation.ROI==roi]\n",
    "    acc = tmp_df.DecodingAccuracy.values\n",
    "    accuracy.append(np.mean(acc))\n",
    "\n",
    "#### Load in accuracies from permutation test\n",
    "nulldist = np.loadtxt(resultdir + 'CrossSubjectLogicalNegationDecoding/CrossSubjectLogicalNegationDecoding_NullDistribution.csv')\n",
    "fwe_thresh = np.max(nulldist[ccn_ind,:],axis=0)\n",
    "fwe_thresh = np.sort(fwe_thresh)\n",
    "alpha_ind = int(len(fwe_thresh)*.95)\n",
    "fwe_thresh = fwe_thresh[alpha_ind]\n",
    "\n",
    "qs = mc.fdrcorrection(ps)[0]\n",
    "accuracy = np.asarray(accuracy)\n",
    "data = np.zeros((len(accuracy),2))\n",
    "data[:,0] = accuracy\n",
    "data[ccn_ind,1] = np.multiply(accuracy[ccn_ind],accuracy[ccn_ind]>fwe_thresh)\n",
    "tools.mapBackToSurface(data,resultdir + 'LogicalNegationDecoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify which regions are sensitive to task performance (correct v. error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance = pd.read_csv(resultdir + 'CrossSubjectPerformanceDecoding/CrossSubjectPerformanceDecoding_allROIs.csv')\n",
    "chance = 0.5\n",
    "rois = np.unique(df_performance.ROI)\n",
    "accuracy = []\n",
    "ps = []\n",
    "for roi in np.sort(rois):\n",
    "    tmp_df = df_performance.loc[df_performance.ROI==roi]\n",
    "    acc = tmp_df.DecodingAccuracy.values\n",
    "    accuracy.append(np.mean(acc))\n",
    "\n",
    "#### Load in accuracies from permutation test\n",
    "nulldist = np.loadtxt(resultdir + 'CrossSubjectPerformanceDecoding/CrossSubjectPerformanceDecoding_NullDistribution.csv')\n",
    "fwe_thresh = np.max(nulldist[ccn_ind,:],axis=0)\n",
    "fwe_thresh = np.sort(fwe_thresh)\n",
    "alpha_ind = int(len(fwe_thresh)*.95)\n",
    "fwe_thresh = fwe_thresh[alpha_ind]\n",
    "\n",
    "qs = mc.fdrcorrection(ps)[0]\n",
    "accuracy = np.asarray(accuracy)\n",
    "data = np.zeros((len(accuracy),2))\n",
    "data[:,0] = accuracy\n",
    "data[ccn_ind,1] = np.multiply(accuracy[ccn_ind],accuracy[ccn_ind]>fwe_thresh)\n",
    "tools.mapBackToSurface(data,resultdir + 'PerformanceDecoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results for 64 task decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.arange(1,361)\n",
    "chance = 1/64.0\n",
    "accuracy = []\n",
    "ps = []\n",
    "for roi in np.sort(rois):\n",
    "    df_64 = pd.read_csv(resultdir + 'CrossSubject64TaskDecoding/CrossSubject64TaskDecoding_roi' + str(roi) + '.csv')\n",
    "    subjs = np.unique(df_64.Subject.values)\n",
    "    subjaccuracy = []\n",
    "    for subj in subjs:\n",
    "        tmpdf = df_64.loc[df_64.Subject==subj]\n",
    "        acc = np.mean(tmpdf.DecodingAccuracy.values)\n",
    "        subjaccuracy.append(acc)\n",
    "    t, p = stats.ttest_1samp(subjaccuracy,chance)\n",
    "    p = p/2.0 if np.mean(subjaccuracy)>chance else 1.0-p/2.0\n",
    "    ps.append(p)\n",
    "    accuracy.append(np.mean(subjaccuracy))\n",
    "\n",
    "qs = mc.fdrcorrection(ps)[0]\n",
    "accuracy = np.asarray(accuracy)\n",
    "sig_acc = np.multiply(accuracy,qs)\n",
    "data = np.zeros((len(accuracy),2))\n",
    "data[:,0] = accuracy\n",
    "data[:,1] = sig_acc\n",
    "tools.mapBackToSurface(data,resultdir + '64TaskDecoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results for logic rule decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.arange(1,361)\n",
    "chance = 1/4.0\n",
    "accuracy = []\n",
    "ps = []\n",
    "for roi in np.sort(rois):\n",
    "    df_logic = pd.read_csv(resultdir + 'CrossSubjectLogicRuleDecoding/CrossSubjectLogicRuleDecoding_roi' + str(roi) + '.csv')\n",
    "    subjs = np.unique(df_logic.Subject.values)\n",
    "    subjaccuracy = []\n",
    "    for subj in subjs:\n",
    "        tmpdf = df_logic.loc[df_logic.Subject==subj]\n",
    "        acc = np.mean(tmpdf.DecodingAccuracy.values)\n",
    "        subjaccuracy.append(acc)\n",
    "    t, p = stats.ttest_1samp(subjaccuracy,chance)\n",
    "    p = p/2.0 if np.mean(subjaccuracy)>chance else 1.0-p/2.0\n",
    "    ps.append(p)\n",
    "    accuracy.append(np.mean(subjaccuracy))\n",
    "\n",
    "qs = mc.fdrcorrection(ps)[0]\n",
    "accuracy = np.asarray(accuracy)\n",
    "sig_acc = np.multiply(accuracy,qs)\n",
    "data = np.zeros((len(accuracy),2))\n",
    "data[:,0] = accuracy\n",
    "data[:,1] = sig_acc\n",
    "tools.mapBackToSurface(data,resultdir + 'LogicRuleDecoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results for sensory rule decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.arange(1,361)\n",
    "chance = 1/4.0\n",
    "accuracy = []\n",
    "ps = []\n",
    "for roi in np.sort(rois):\n",
    "    df_sensory = pd.read_csv(resultdir + 'CrossSubjectSensoryRuleDecoding/CrossSubjectSensoryRuleDecoding_roi' + str(roi) + '.csv')\n",
    "    subjs = np.unique(df_sensory.Subject.values)\n",
    "    subjaccuracy = []\n",
    "    for subj in subjs:\n",
    "        tmpdf = df_sensory.loc[df_logic.Subject==subj]\n",
    "        acc = np.mean(tmpdf.DecodingAccuracy.values)\n",
    "        subjaccuracy.append(acc)\n",
    "    t, p = stats.ttest_1samp(subjaccuracy,chance)\n",
    "    p = p/2.0 if np.mean(subjaccuracy)>chance else 1.0-p/2.0\n",
    "    ps.append(p)\n",
    "    accuracy.append(np.mean(subjaccuracy))\n",
    "\n",
    "qs = mc.fdrcorrection(ps)[0]\n",
    "accuracy = np.asarray(accuracy)\n",
    "sig_acc = np.multiply(accuracy,qs)\n",
    "data = np.zeros((len(accuracy),2))\n",
    "data[:,0] = accuracy\n",
    "data[:,1] = sig_acc\n",
    "tools.mapBackToSurface(data,resultdir + 'SensoryRuleDecoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results for motor rule decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.arange(1,361)\n",
    "chance = 1/4.0\n",
    "accuracy = []\n",
    "ps = []\n",
    "for roi in np.sort(rois):\n",
    "    df_motor = pd.read_csv(resultdir + 'CrossSubjectMotorRuleDecoding/CrossSubjectMotorRuleDecoding_roi' + str(roi) + '.csv')\n",
    "    subjs = np.unique(df_motor.Subject.values)\n",
    "    subjaccuracy = []\n",
    "    for subj in subjs:\n",
    "        tmpdf = df_motor.loc[df_logic.Subject==subj]\n",
    "        acc = np.mean(tmpdf.DecodingAccuracy.values)\n",
    "        subjaccuracy.append(acc)\n",
    "    t, p = stats.ttest_1samp(subjaccuracy,chance)\n",
    "    p = p/2.0 if np.mean(subjaccuracy)>chance else 1.0-p/2.0\n",
    "    ps.append(p)\n",
    "    accuracy.append(np.mean(subjaccuracy))\n",
    "\n",
    "qs = mc.fdrcorrection(ps)[0]\n",
    "accuracy = np.asarray(accuracy)\n",
    "sig_acc = np.multiply(accuracy,qs)\n",
    "data = np.zeros((len(accuracy),2))\n",
    "data[:,0] = accuracy\n",
    "data[:,1] = sig_acc\n",
    "tools.mapBackToSurface(data,resultdir + 'MotorRuleDecoding')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
